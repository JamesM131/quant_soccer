---
title: "Basic Neural Network Trial"
author: "James Monks"
date: "09/09/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
source(here::here("R", "read-utils.R"))
```

# Preface
The groundtruth data will be used for identifying the location of each player when training the neural network. This will be used in combination with the landmark data as predictor variables.

The data being used to test this is from a game that has Gliders as the left team and HELIOS as the right. This is important as the groundtruth data isnt structured in a way that uses team names, which means the correct player will be extracted using the side and the number. 

For this initial run, gliders player 2 will be used.

# Structuring The Data
# Read in the data
Get the groundtruth data and select only the columns for the gliders player 2.
```{r}
player_2_truth <- read_ground_truth() %>% 
  select(l2_x, l2_y)
head(player_2_truth)
```


## Obtaining Independant Variables

Now obtain the observed landmark data for this player. This data will be transformed in order to create a set of standard inputs into the neural network. This will be done through first obtaining the 3 closest station measurements of angle and distance and then connecting the station coordinates. This means that the 12 inputs into the model for this basic run will be 3 distances, 3 angles and 3 sets of coordinates.




>**Note:** There is an issue in obtaining the values for each time increment, as these increments are not unique. This is because during the "foul_charge" playode time does not pass, but players are still moving around. In the case of the groundtruth data, the row number of the data set may be considered to be a unique time index, however, for the case of the percieved data the row number does not suffice, as the frequency of updates is dependant on the current field of view for the player. 

This means that there must be a custom time index created for the perceived data to match to the corresponding ground truth row. This is explored in more detail in the document "Correction of the Percieved Time Index". For the remainder of this document however *duplicated time indexes will be removed* which is okay as the basic neural network is not taking into account only independant samples of the data.

The following takes the percieved landmark data, removes the duplicated time indexes and obtains the closest 3 landmarks. 

```{r}
player_2_landmarks <- 
  read_landmarks("Gliders", 2) %>% 
  filter(number_time != 0) %>% 
  distinct(number_time, .keep_all = TRUE) %>% 
  pivot_longer(-number_time, names_to  = "landmark") %>% 
  filter(is.nan(value) == FALSE) %>% 
  separate(landmark, sep = "_(?=[a-z]{2,})", into = c("landmark", "metric")) %>% 
  filter(metric %in% c("dist", "angle")) %>% 
  pivot_wider(names_from = metric, values_from = value) %>% 
  group_by(number_time) %>% 
  top_n(3, dist) %>% 
  slice(1:3) 

```


This data only contains the names of the landmarks, however, the coordinates would be much more informative. This would allow the relative positions of flags to one another to be included in the model. 
```{r}
landmarks <- read_csv(here::here("data-raw", "landmarks.csv"))
player_2_connected <- player_2_landmarks %>% 
  left_join(landmarks)
```


This data needs to be shaped in a way that is accessible to a neural network. This means that there needs to be one angle for each observation. 

The following creates variables for the flag numbers and distances/angles along with theie x and y coordinates.

```{r}
long_independant_variables <- player_2_connected %>%
  mutate(flag_num = as.character(glue::glue("flag_{1:n()}"))) %>%
  ungroup() %>%
  pivot_longer(dist:y) %>% 
  unite("flag_num", flag_num:name) %>% 
  select(-landmark) %>% 
  pivot_wider(names_from = c(flag_num)) %>% 
  na.omit()

```


## Obtain the Dependant Variables
The dependant variables in this case are the x and y coordinates of the player at any given time. This information is stored in the ground truth data for all players. It can be accessed for player 2 of the gliders team in this case.

*Note: the player that is currently being considered is from the left team and is number 2.*
```{r}
raw_ground_truth <- read_ground_truth() %>% 
  select(number_time, l2_x, l2_y)
```

This data needs to be connected to the player perception data, however as mentioned before, there are a number of problems around this due to the time indexes. As was done with the previous data, only distinct occurrences of the time index will be considered. 

```{r}
long_dependant_variables <- raw_ground_truth %>%
  distinct(number_time, .keep_all = TRUE) %>% 
  rename(x = l2_x, y = l2_y) %>% 
  na.omit()
```

## Connecting the data
The ground truth data has many more observations than the percieved data due to the update frequency of the player which is based on their field of view. This means that the dependant variables cannot be used dierctly. They will be connected to the perceived data along with having a filtered copy made of them for ease of use in models.

There is a known error with the time indexes that are used to connect the dependant and independant variables in that the dependant variables (ground truth) do not contain a value for the half time point (in this case 3000). This means that both objects need to be resized to fit the other. 

```{r}
connected_data <- long_independant_variables %>% 
  left_join(long_dependant_variables)

dependant_variables <- long_dependant_variables %>% 
  semi_join(long_independant_variables)

independant_variables <- long_independant_variables %>% 
  semi_join(long_dependant_variables)
```


## Testing a Simple Feed Forward Neural Network
The neural networks will be implemented in Keras. There is an implementation of this framework in R which would suffice for the needs of this application, however it is not as flexible as its python implementation. For this reason the python implementation will be prefered, however the R interface will be used to demonstrate both implentations of the framework.

In order to operate with the data sets that have been built in R the reticulate package will be used as an interface. 

```{r}
library(reticulate)
```


Now python code chunks that utilise the r objects can be used. 

Load packages
```{python}
import pandas
# from keras.models import Sequential
from keras.layers import Input, Dense
from keras.models import Model

from keras.wrappers.scikit_learn import KerasRegressor
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import KFold
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.metrics import accuracy_score

# Set a seed for replication
seed = 1
```


In this case the output is 2 dimensional (i.e. the x coordinate and the y coordinate). This means that the keras functional api must be used as opposed to the sequential api. This is because the sequential api will throw an error if 2 outputs are expected.

```{python}
independant_variables = r.independant_variables.values
print(independant_variables)

X = independant_variables[:,1:13]
Y = independant_variables[:,1:3]

```



```{python}
X.shape
Y.shape
```

First defining the input layer with size = 12:
```{python}
input_layer = Input(shape = (12, ))
```

Now defining the remaining structure of the network:
```{python}
x = Dense(8, activation='relu')(input_layer)
x = Dense(5, activation='relu')(x)
outputs = Dense(2, activation = "linear")(x)
```


Now create a model by combining the two and copmile it:
```{python}
model = Model(inputs = input_layer, outputs = outputs)
model.compile(loss = "mse", optimizer = "adam")
```


This can all be put into a function in order to use cross validation utilities.
```{python}
def base_nn():
  input_layer = Input(shape = (12, ))
  x = Dense(8, activation='relu')(input_layer)
  x = Dense(5, activation='relu')(x)
  outputs = Dense(2, activation = "linear")(x)
  model = Model(inputs = input_layer, outputs = outputs)
  model.compile(loss = "mse", optimizer = "adam")
  return model


```

And evaluationg:
```{python}

estimator = KerasRegressor(build_fn=base_nn, nb_epoch=100, batch_size=100, verbose=False)
kfold = KFold(n_splits=10, random_state=seed)
results = cross_val_score(estimator, X, Y, cv=kfold)
print("Results: %.2f (%.2f) MSE" % (results.mean(), results.std()))

estimator.fit(X, Y)
prediction = estimator.predict(X)

```


Finally fitting the raw model to the data:
```{python}
# model.fit(X, Y, validation_split=0.33, epochs=150, batch_size=10)
model.fit(X, Y)
```



Now the structure of the neural network can be changed along with the input styles. The number of layers and the number of neurons per layer in this case were chosen somewhat at random (numbers being kept in the neighbourhood of the input and then scaling down through the hidden layers).

**It would also be good to train seperate networks for the X and Y coordinate explicitly. **





# TODO: Work on the larger data set information
## Creating a larger data set
For this simple architecture, with independant samples, there is no reason not to include all of the players, as each obervation is being treated as independant anyway. 

### Issues to be addressed with this approach
* Naming conventions in the ground truth data
* Distributed files
* Different Teams and Numbers

### Collecting Data
To collect all of the groundtruth locations, any variable that ends in "_x" or "_y" will be used.
```{r}
read_ground_truth() %>%
  select(c(ends_with("_x"), ends_with("_y")), -starts_with("ball"))
```

